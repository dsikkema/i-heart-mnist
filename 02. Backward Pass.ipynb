{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d261939a-6246-45fc-9318-327815d814c3",
   "metadata": {},
   "source": [
    "This notebook, for now, is best seen as a working, concrete illustration of how these concepts look in python, to supplement other resources that explain the concepts more effectively.\n",
    "\n",
    "The most important resource I used to build the code here was [Simple Neural Net Backward Pass](https://nasheqlbrm.github.io/blog/posts/2021-11-13-backward-pass.html) (which covers everything but gradients for Cross Entropy Loss and softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b682b1f5-541b-48e9-b8ab-1de4d15ceac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40979f1-4ac3-4ac4-9756-0188ac4c01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b3a19e-fef5-41c5-83be-0af4c4077679",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "\n",
    "if not path_gz.exists():\n",
    "    urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b108a17e-a5f8-49e8-86fa-b8e79a7ab024",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    \n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbed8c79-abbf-4ba2-9c06-340dabf160ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE=x_train.shape[0]\n",
    "BATCH_SIZE=10000\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8532d5c6-3cca-4e83-b245-b36c3c7577aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size):\n",
    "    '''\n",
    "    Xavier Weight Initialization\n",
    "    strategy for initializing values of weights meant to prevent gradient vanishing or explosion.\n",
    "    '''\n",
    "    bound = math.sqrt(1.0 / size[0])\n",
    "    return torch.randn(size).uniform_(-bound, bound)\n",
    "\n",
    "'''\n",
    "implementation below does not use LogSumExp trick to ensure numerical stability.\n",
    "'''\n",
    "def softmax(x):\n",
    "    e=x.exp()\n",
    "    return e / e.sum(-1,keepdim=True)\n",
    "\n",
    "def CrossEntropyLoss(p,y):\n",
    "    losst = -(p[range(p.shape[0]),y].log())\n",
    "    result = losst.mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd51f57-0fb8-4205-b2fd-04c582b122bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = init_params((784, 200)) # \n",
    "bias1    = init_params((200, ))\n",
    "\n",
    "weights2 = init_params((200, 10))\n",
    "bias2    = init_params((10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63a7ad-56ab-44f6-b152-b9f6f340b9eb",
   "metadata": {},
   "source": [
    "We will start by working through individual cells to build up a single pass up prediction and backpropagation before we even try to put any of it into functions. Our batch_size will be 7, so we expect to see that number (along with the dimensions of various parameter tensors, like the number of features for input, hidden, and output layers) in lots of \"intermediate\" gradient dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0ad695-be16-4471-b6c5-e5140a83d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=7\n",
    "\n",
    "x=x_train[0:bs]\n",
    "y=y_train[0:bs]\n",
    "\n",
    "# For each feature of the hidden layer, sum the products of each input feature with a corresponding weight and add a bias\n",
    "z1 = (x @ weights1 + bias1)\n",
    "\n",
    "# This is relu aka rectified linear unit activation\n",
    "a1 = z1.max(tensor(0.0))\n",
    "\n",
    "z2 = (a1 @ weights2 + bias2)\n",
    "\n",
    "preds = softmax(z2)\n",
    "\n",
    "L = CrossEntropyLoss(preds, y)\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d92554-06d1-49cf-82a6-73b092b8bb06",
   "metadata": {},
   "source": [
    "batch size = 7\n",
    "out features = 10\n",
    "hidden features = 1000\n",
    "in features = 784\n",
    "\n",
    "we want:\n",
    "\n",
    "dL/dweights1, size=(784, 1000)\n",
    "\n",
    "  = dL/dsoftmax * dsoftmax/dz2 * dz2/da1 * da1/dz1 * dz1/dweights1\n",
    "\n",
    "dL/dbias1, size = (1000,)\n",
    "\n",
    "  = dL/dsoftmax * dsoftmax/dz2 * dz2/da1 * da1/dz1 * dz1/dbias1\n",
    "  \n",
    "dL/dweights2, size=(1000, 10)\n",
    "\n",
    "  = dL/dsoftmax * dsoftmax/dz2 * dz2/dweights2\n",
    "  \n",
    "dL/dbias2, size=(10)\n",
    "\n",
    "  = dL/dsoftmax * dsoftmax/dz2 * dz2/dbias2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb5e02-0c0a-455f-b190-e6805d3bcfef",
   "metadata": {},
   "source": [
    "For a given example from a batch, if p is the prediction of the actual value according to the label, then dL/dsoftmax is:\n",
    "$$\n",
    "    (\\frac{-1}{Np})\n",
    "$$\n",
    "Note that because softmax values other than the argmax don't affect the loss for that example, they zero out\n",
    "\n",
    "The following code works out a matrix dL/dsoftmax over all the examples and softmax values in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee192d4-f78b-44a1-8e0c-65fe9558f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00,  0.00,  0.00,  0.00,  0.00, -1.42,  0.00,  0.00,  0.00,  0.00],\n",
       "        [-1.36,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "        [ 0.00,  0.00,  0.00,  0.00, -1.36,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "        [ 0.00, -1.49,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "        [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00, -1.29],\n",
       "        [ 0.00,  0.00, -1.62,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "        [ 0.00, -1.64,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dsoft = torch.zeros((7,10))\n",
    "dL_dsoft[range(y.shape[0]), y] = -1.0/(preds.shape[0] * preds[range(y.shape[0]), y])\n",
    "dL_dsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2d738-3e42-4256-8fef-2a24cdab6a32",
   "metadata": {},
   "source": [
    "dsoft/dz with be a matrix size (out_features, out_features) or (10, 10) because there are 10 output activations, and each of them has an influence on each of the 10 softmax outputs.\n",
    "\n",
    "for a given training example, the $i$th softmax is:\n",
    "$$\n",
    "\\frac{e^{z_i}}{e^{z_0} + e^{z_1} + \\cdots + e^{z_{10}}}\n",
    "$$\n",
    "\n",
    "in other words\n",
    "$$\n",
    "\\frac{e^{z_i}}{\\sum_{j=0}^{d} e^{z_j}}\n",
    "$$\n",
    "Letting d=out_features, the derivative of the $k$th softmax with regard to ${z_i}$, if $i {\\ne} k$, is:\n",
    "$$\n",
    "e^{z_i} e^{z_k} \\frac{-1}{(\\sum_{j=0}^{d} e^{z_j})^2}\n",
    "$$\n",
    "\n",
    "except if i=k then there is an additional term added (the numerator is not a constant but a function and hence the product rule must be used). That makes the derivative of the $i$th softmax with regard to the $z_i$ look like this:\n",
    "$$\n",
    "e^{2z_i} \\frac{-1}{(\\sum_{j=0}^{d} e^{z_j})^2} + e^{z_i} \\frac{1}{\\sum_{j=0}^{d} e^{z_j}}\n",
    "$$\n",
    "\n",
    "For a given training example, letting rows indicate z values (differentiated variables) and columns indicate softmax values for which the derivative is being computed, dsoft/dz will be a matrix whose values are the first equation everywhere except the diagonals and the second equation along the diagonals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a3e2a-8e83-4ef2-9e53-cf6a856fe786",
   "metadata": {},
   "source": [
    "Lets, for convenience, make a vector of e raised to the power of every z, and make it a column vector by appending a unit-dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b308d6ff-f95f-4c87-984e-d23204ce7c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2exp = z2.exp()[...,None]\n",
    "z2exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04e381-7f11-40a1-969a-218aea745d50",
   "metadata": {},
   "source": [
    "Computing the full matrix of dlsoft/dz (in other words, for each softmax output, derivative with regard to each $z_i$ which contributed to it) is not necessary since most of them get zeroed out when calculating the gradients we actually want: dL/dsoft is 0 for all but one softmax output in a given example. However we'll just calculate the whole matrix even though most of the columns in a given example will get ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00882d3-459f-4c4b-a603-4394af7f27b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = z2exp @ torch.einsum('abc->acb', z2exp)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a46ec4-023b-4984-82cd-88760aab923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expsum = z2exp.sum(dim=1, keepdim=True)\n",
    "expsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ed2998-4df9-4d42-94d1-df52d4d558b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = m * (-1. / expsum.pow(2))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a92d87-cc0c-4a7a-b9a7-339df5c39eb0",
   "metadata": {},
   "source": [
    "Compute the additional term to be added onto the diagonals to complete the matrix of gradients while getting rid of the last unit dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "690e52e7-09c9-4a69-a01b-40659b733814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal_term = (1.0/expsum)*z2exp\n",
    "diagonal_term=diagonal_term[...,0]\n",
    "diagonal_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0e7e633-7fd3-443f-bba3-783bfd5b2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[:,range(z2.shape[1]),range(z2.shape[1])] += diagonal_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "264a921b-aae2-401d-b072-426b3a7b26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsoft_dz2 = m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c44a1-d8b8-4842-83c7-744dac0ddf13",
   "metadata": {},
   "source": [
    "Having now dL/dsoft and dsoft/dz we can compute dL/dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec955fa-85fc-4b87-8838-b972b21c0e89",
   "metadata": {},
   "source": [
    "The mutivariate chain rule says that if we have a function combining other functions of x, like $f(g_1(x), g_2(x), \\ldots, g_n(x))$, then the derivative of f with regard to x will be the dot product of the vector of derivatives $\\frac{df}{dg_i}$ (for i in $0 \\ldots n$) and $\\frac{dg_i}{dx}$. We use matrix multiplication to get the dot products of (a) the derivative of Loss with regard to each softmax output for each example, and (b) the derivative of each softmax of an example with regard to a particular $z_i$. Each of those dot products will correspond to a $\\frac{dL}{dz_i}$ and each example will produce a vector, the gradients for z. Hence over all examples it will be a matrix of size (batch_size x out_features). And of course, we add and remove a unit dimension in order to properly align the dimensions we're trying to dot-product and then remove the extra that we added afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd5a32a-838f-46a5-aeba-a3780f7a88ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dsoft.shape,dsoft_dz2.shape\n",
    "dL_dz2=(dL_dsoft[:,None,:] @ dsoft_dz2)[:,0,:]\n",
    "dL_dz2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff13e6-aaad-428f-9496-590ed43ba5f7",
   "metadata": {},
   "source": [
    "The partial derivative of output with regard to a weight is just the sum over each input which got multiplied by that weight during matrix multiplication. The \"inputs\" are just \"constant multiples\" when the weights are viewed as the variable being differentiated against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1296281-f504-470b-acd7-404d9f49767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dweights2 = a1.t() @ dL_dz2\n",
    "dL_dweights2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d4d45-d29b-4d95-9e2d-8ce5448d8ebb",
   "metadata": {},
   "source": [
    "Each bias parameter contributes to only one $z$ output and because it's just added onto a bunch of previous multiplication of weights and inputs, $\\frac{dz_i}{db_i}$ is always 1. So the vector of such partial derivatives is a vector of all ones. Hence, and in combination with the \"multivariable chain rules are dot products\" principle above, $\\frac{dL}{db_i}$ is just the sum of $\\frac{dL}{dz_i}$ summed over the training examples for which $z_i$ was calculated (that's what you get when you dot product a vector against a vector of ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9ef7e4-2285-47d3-9379-de2a722e0452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dbias2 = dL_dz2.sum(0)\n",
    "dL_dbias2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb78db-e939-4968-b606-d2deb77da51f",
   "metadata": {},
   "source": [
    "Now find the gradient for the input of the second linear layer. The partial of an output value for any given input is just a sum of weights, which are constant coefficients in this perspective, so we line up the output gradient with the weights which comprise the corresponding partials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dbffed6-27d9-4334-b0ad-e88f07500ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_da1 = dL_dz2 @ weights2.t()\n",
    "dL_da1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a267100-e61b-4428-94e8-5bae828cf0c6",
   "metadata": {},
   "source": [
    "a1 came out of a relu, so it's value is just the corresponding z1 (if greater than 0) or 0 elsewise. In the former case, the partial is 1, in the latter, you're finding the derivative of a constant so it's 0. Therefore  $\\frac{da1}{dz_1}$ is a vector of 0s and 1s = ($z_i$ > 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f51fd100-244d-4e0b-97ea-c030c4f8d412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da1_dz1 = (z1 > 0).float()\n",
    "da1_dz1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02b6d500-8760-4c5d-9f26-dee125d4fca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dz1 = dL_da1 * da1_dz1\n",
    "dL_dz1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da30758-fd65-4b64-bd77-f839350804f0",
   "metadata": {},
   "source": [
    "Now we repeat the steps above for finding gradients for weights and biases of a linear layer, given the gradient of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f768ef46-f2a8-4e5f-8619-d3c97a2d144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 784]), torch.Size([784, 200]), torch.Size([7, 200]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,weights1.shape,dL_dz1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c02b014a-92bf-4276-98d7-7308c4d6f902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 200])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dweights1 = x.t() @ dL_dz1\n",
    "dL_dweights1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5981249f-1466-43e1-b86f-b8130f789bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dbias1 = dL_dz1.sum(0)\n",
    "dL_dbias1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a8a23-9e98-416c-9a24-ba651bb3ee2e",
   "metadata": {},
   "source": [
    "Well that's it. Now update parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0419948b-8f82-4070-834d-6fe6258845c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 -= LEARNING_RATE * dL_dweights1\n",
    "weights2 -= LEARNING_RATE * dL_dweights2\n",
    "bias1 -= LEARNING_RATE * dL_dbias1\n",
    "bias2 -= LEARNING_RATE * dL_dbias2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88981d-ee0d-4746-844f-27aeae41fb19",
   "metadata": {},
   "source": [
    "Now in order to do training over batches and epochs, we'll combine all that huge cludgy code into one function that will:\n",
    "- make prediction\n",
    "- calculate loss\n",
    "- backpropagate the gradients of loss to parameters\n",
    "- return both predictions and loss\n",
    "\n",
    "Then we'll loop over that function to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f8b82e-8550-4799-9c01-00dd36cbad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomebrewModel:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        784: number of input features (pixels in 28x28 image)\n",
    "        200: number of feaures in the hidden layer (can be arbitrarily chosen)\n",
    "        '''\n",
    "        self.weights1 = init_params((784, 1000)) # \n",
    "        self.bias1    = init_params((1000, ))\n",
    "        '''\n",
    "        200: match the output coming from features of hidden layer\n",
    "        10: 10 possible output classifications (corresponding to the digits 0-9)\n",
    "        '''\n",
    "        self.weights2 = init_params((1000, 10))\n",
    "        self.bias2    = init_params((10,))\n",
    "        \n",
    "    '''\n",
    "    Sets gradients on parameters before returning\n",
    "    \n",
    "    return (predictions,loss)\n",
    "    '''\n",
    "    def predict_and_backpropagate(self, x, y):\n",
    "        z1 = (x @ self.weights1 + self.bias1)\n",
    "        a1 = z1.max(tensor(0.0))\n",
    "        z2 = (a1 @ self.weights2 + self.bias2)\n",
    "        preds = softmax(z2)\n",
    "        L = CrossEntropyLoss(preds, y)\n",
    "\n",
    "        dL_dsoft = torch.zeros(preds.shape)\n",
    "        dL_dsoft[range(y.shape[0]), y] = -1.0/(preds.shape[0] * preds[range(y.shape[0]), y])\n",
    "        z2exp = z2.exp()[...,None]\n",
    "        m = z2exp @ torch.einsum('abc->acb', z2exp)\n",
    "        expsum = z2exp.sum(dim=1, keepdim=True)\n",
    "        m = m * (-1. / expsum.pow(2))\n",
    "        diagonal_term = (1.0/expsum)*z2exp\n",
    "        diagonal_term = diagonal_term.squeeze()\n",
    "        m[:,range(z2.shape[1]),range(z2.shape[1])] += diagonal_term\n",
    "\n",
    "        dsoft_dz2 = m\n",
    "        dL_dz2=(dL_dsoft[:,None,:] @ dsoft_dz2)[:,0,:]\n",
    "        dL_dweights2 = a1.t() @ dL_dz2\n",
    "        dL_dbias2 = dL_dz2.sum(0)\n",
    "        dL_da1 = dL_dz2 @ self.weights2.t()\n",
    "        da1_dz1 = (z1 > 0).float()\n",
    "        dL_dz1 = dL_da1 * da1_dz1\n",
    "        dL_dweights1 = x.t() @ dL_dz1\n",
    "        dL_dbias1 = dL_dz1.sum(0)\n",
    "\n",
    "        self.weights1.diy_grad = dL_dweights1\n",
    "        self.weights2.diy_grad = dL_dweights2\n",
    "        self.bias1.diy_grad = dL_dbias1\n",
    "        self.bias2.diy_grad = dL_dbias2   \n",
    "        \n",
    "        return preds,L\n",
    "    \n",
    "    '''\n",
    "    some code duplication of above function, in order to be able to make predictions on validation set without calculating loss\n",
    "    '''\n",
    "    def predict(self, x):\n",
    "        z1 = (x @ self.weights1 + self.bias1)\n",
    "        a1 = z1.max(tensor(0.0))\n",
    "        z2 = (a1 @ self.weights2 + self.bias2)\n",
    "        preds = softmax(z2)\n",
    "        return preds\n",
    "   \n",
    "    def parameters(self):\n",
    "        return [self.weights1, self.bias1, self.weights2, self.bias2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a79c5a64-79e6-460a-a880-b4c419cb2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "epoch goes through entire training set\n",
    "'''\n",
    "def train_epoch(model):\n",
    "    rand_indexes=torch.randperm(TRAIN_SIZE)\n",
    "    '''\n",
    "    each batch is a random subset of the training set, loop over batches to cover all training data\n",
    "    '''\n",
    "    for i in range(0, TRAIN_SIZE, BATCH_SIZE):\n",
    "        # pull the random batch\n",
    "        idxs = rand_indexes[i : i + BATCH_SIZE]\n",
    "        xb = x_train[idxs]\n",
    "        yb = y_train[idxs]\n",
    "        train_batch(model, xb, yb)\n",
    "\n",
    "                \n",
    "    # at the end of epoch, check model performance against validation data\n",
    "    with torch.no_grad():\n",
    "        valid_preds = model.predict(x_valid)\n",
    "        validation_acc = batch_accuracy(valid_preds, y_valid)\n",
    "        validation_loss = CrossEntropyLoss(valid_preds, y_valid)\n",
    "        print(f'valid/acc: {validation_acc}\\t valid/loss: {validation_loss}')\n",
    "\n",
    "def train_batch(model, xb, yb):\n",
    "    preds,loss = model.predict_and_backpropagate(xb, yb)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # update parameters to descend the gradient\n",
    "        for p in model.parameters():\n",
    "            p -= LEARNING_RATE * p.diy_grad\n",
    "            p.diy_grad = None\n",
    "    \n",
    "def batch_accuracy(preds_b, yb):\n",
    "    correct = (preds_b.argmax(1)) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93158cfc-ecaa-4732-81d4-69a9d986cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid/acc: 0.4099999964237213\t valid/loss: 2.160120725631714\n",
      "valid/acc: 0.6890000104904175\t valid/loss: 2.0003321170806885\n",
      "valid/acc: 0.7451000213623047\t valid/loss: 1.8268029689788818\n",
      "valid/acc: 0.7685999870300293\t valid/loss: 1.6401201486587524\n",
      "valid/acc: 0.7850000262260437\t valid/loss: 1.4530173540115356\n",
      "valid/acc: 0.8044000267982483\t valid/loss: 1.2808550596237183\n",
      "valid/acc: 0.820900022983551\t valid/loss: 1.1328946352005005\n",
      "valid/acc: 0.8338000178337097\t valid/loss: 1.0113409757614136\n",
      "valid/acc: 0.8424000144004822\t valid/loss: 0.9131684303283691\n",
      "valid/acc: 0.8482999801635742\t valid/loss: 0.83420330286026\n"
     ]
    }
   ],
   "source": [
    "model = HomebrewModel()\n",
    "for epoch in range(10):\n",
    "    train_epoch(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28772c5-51bc-4cab-b8d9-f693186f98ed",
   "metadata": {},
   "source": [
    "Now to clean this up a substantial degree, we'll refactor each layer of computation into an object that computes it's own gradient when called upon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc009a-0df2-4313-98ca-964ebdb3498b",
   "metadata": {},
   "source": [
    "# Pick a random number and try\n",
    "Run cell below to pick a random number from the training set, see it, and see the prediction made for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbc5130e-0e91-4df2-8c89-86a49f8c7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Confidence: 19.2%\n",
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f683b0888e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = torch.randint(0,TRAIN_SIZE-1, (1,)).item()\n",
    "preds = model.predict(x_train[idx])\n",
    "prediction = preds.argmax()\n",
    "confidence = preds[prediction]\n",
    "print(f'Prediction: {prediction}\\nConfidence: {confidence:.1%}\\nLabel: {y_train[idx]}')\n",
    "plt.imshow(x_train[idx].view(28, 28) * -1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
